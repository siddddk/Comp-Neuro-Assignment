{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61ee379-c410-4e0b-bfbe-b710d52a6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 11:49:43 INFO: Read configs files: /home/bbpnrsoa/sPyNNakerGit/SpiNNUtils/spinn_utilities/spinn_utilities.cfg, /home/bbpnrsoa/sPyNNakerGit/SpiNNMachine/spinn_machine/spinn_machine.cfg, /home/bbpnrsoa/sPyNNakerGit/PACMAN/pacman/pacman.cfg, /home/bbpnrsoa/sPyNNakerGit/SpiNNMan/spinnman/spinnman.cfg, /home/bbpnrsoa/sPyNNakerGit/SpiNNFrontEndCommon/spinn_front_end_common/interface/spinnaker.cfg, /home/bbpnrsoa/sPyNNakerGit/sPyNNaker/spynnaker/pyNN/spynnaker.cfg, /home/bbpnrsoa/.spynnaker.cfg\n",
      "2024-04-25 11:49:43 INFO: Will search these locations for binaries: /home/bbpnrsoa/sPyNNakerGit/sPyNNaker/spynnaker/pyNN/model_binaries\n",
      "2024-04-25 11:49:43 WARNING: A timestep was entered that has forced spinnaker to automatically slow the simulation down from real time by a factor of 10.\n",
      "2024-04-25 11:49:43 INFO: Setting hardware timestep as 1000 microseconds based on simulation time step of 100 and timescale factor of 10\n",
      "2024-04-25 11:49:43 INFO: Starting execution process\n",
      "2024-04-25 11:49:43 INFO: Simulating for 10000 0.1 ms timesteps using a hardware timestep of 1000 us\n",
      "2024-04-25 11:49:44 INFO: SpYNNakerNeuronGraphNetworkSpecificationReport skipped as cfg Reports:write_network_graph is False\n",
      "2024-04-25 11:49:44 INFO: Network Specification report took 0:00:00.000894 \n",
      "2024-04-25 11:49:44 INFO: Splitter reset took 0:00:00.000044 \n",
      "Adding Splitter selectors where appropriate\n",
      "|0%                          50%                         100%|\n",
      " ===================================="
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/bbpnrsoa/sPyNNakerGit/SpiNNUtils/spinn_utilities/spinn_utilities.cfg', '/home/bbpnrsoa/sPyNNakerGit/SpiNNMachine/spinn_machine/spinn_machine.cfg', '/home/bbpnrsoa/sPyNNakerGit/PACMAN/pacman/pacman.cfg', '/home/bbpnrsoa/sPyNNakerGit/SpiNNMan/spinnman/spinnman.cfg', '/home/bbpnrsoa/sPyNNakerGit/SpiNNFrontEndCommon/spinn_front_end_common/interface/spinnaker.cfg', '/home/bbpnrsoa/sPyNNakerGit/sPyNNaker/spynnaker/pyNN/spynnaker.cfg', '/home/bbpnrsoa/.spynnaker.cfg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========================\n",
      "2024-04-25 11:49:44 INFO: Spynnaker splitter selector took 0:00:00.072055 \n",
      "Adding delay extensions as required\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:49:44 INFO: DelaySupportAdder took 0:00:00.080016 \n",
      "Partitioning Graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:49:44 INFO: Splitter partitioner took 0:00:00.072651 \n",
      "2024-04-25 11:49:44 INFO: 0.02 Boards Required for 1 chips\n",
      "2024-04-25 11:49:44 INFO: Requesting job with 1 boards\n",
      "Created spalloc job 439170\n",
      "2024-04-25 11:49:44 INFO: Created spalloc job 439170\n",
      "Job has been queued by the spalloc server.\n",
      "2024-04-25 11:49:44 INFO: Job has been queued by the spalloc server.\n",
      "Waiting for board power commands to complete.\n",
      "2024-04-25 11:49:48 INFO: Waiting for board power commands to complete.\n",
      "2024-04-25 11:49:57 INFO: SpallocAllocator took 0:00:13.071839 \n",
      "2024-04-25 11:49:57 INFO: Creating transceiver for 10.11.238.185\n",
      "2024-04-25 11:49:57 INFO: Working out if machine is booted\n",
      "2024-04-25 11:50:01 INFO: Attempting to boot machine\n",
      "2024-04-25 11:50:07 INFO: Found board with version [Version: SC&MP 3.4.2 at SpiNNaker:0:0:0 (built Fri Jun 10 17:21:19 2022)]\n",
      "2024-04-25 11:50:07 INFO: Machine communication successful\n",
      "2024-04-25 11:50:07 INFO: 10.11.238.185\n",
      "2024-04-25 11:50:07 INFO: Detected a machine on IP address 10.11.238.185 which has 838 cores and 114.0 links\n",
      "2024-04-25 11:50:07 INFO: Machine generator took 0:00:09.986191 \n",
      "2024-04-25 11:50:07 INFO: Json machine skipped as cfg Reports:write_json_machine is False\n",
      "Writing the board chip report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Board chip report took 0:00:00.018613 \n",
      "Adding commands\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Command Sender Adder took 0:00:00.017954 \n",
      "2024-04-25 11:50:07 INFO: Split Live Gather Vertices took 0:00:00.000031 \n",
      "2024-04-25 11:50:07 INFO: Insert chip power monitors skipped as cfg Reports:write_energy_report is False\n",
      "2024-04-25 11:50:07 INFO: Insert extra monitor vertices took 0:00:00.000063 \n",
      "Inserting extra monitors into graphs\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating partitioner report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Partitioner report took 0:00:00.010871 \n",
      "2024-04-25 11:50:07 INFO: Local TDMA builder took 0:00:00.000158 \n",
      "Placing Vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Application Placer took 0:00:00.006795 \n",
      "Generating placement report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating placement by core report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Placements wth application graph report took 0:00:00.057145 \n",
      "2024-04-25 11:50:07 INFO: Json placements skipped as cfg Reports:write_json_placements is False\n",
      "Generating routing tables for data in system processes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: System multicast routing generator took 0:00:00.006280 \n",
      "Generating fixed router routes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Fixed route router took 0:00:00.008613 \n",
      "Routing\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Application Router took 0:00:00.018737 \n",
      "Allocating tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Basic tag allocator took 0:00:00.033157 \n",
      "Reporting Tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Tag allocator report took 0:00:00.003574 \n",
      "Calculating zones\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Allocating routing keys\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Zoned routing info allocator took 0:00:00.046991 \n",
      "Generating Routing info report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "2024-04-25 11:50:07 INFO: Router info report took 0:00:00.006621 \n",
      "Generating routing tables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Merged routing table generator took 0:00:00.003377 \n",
      "Generating Router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Uncompressed routing table report took 0:00:00.003660 \n",
      "2024-04-25 11:50:07 INFO: Router report skipped as cfg Reports:write_router_reports is False\n",
      "2024-04-25 11:50:07 INFO: Router summary report skipped as cfg Reports:write_router_summary_report is False\n",
      "2024-04-25 11:50:07 INFO: Json routing tables skipped as cfg Reports:write_json_routing_tables is False\n",
      "2024-04-25 11:50:07 INFO: Locate executable start type took 0:00:00.000409 \n",
      "2024-04-25 11:50:07 INFO: Buffer manager creator took 0:00:00.002150 \n",
      "2024-04-25 11:50:07 INFO: Write Neo Metadata took 0:00:00.027647 \n",
      "2024-04-25 11:50:07 INFO: Record vertex labels to database took 0:00:00.002996 \n",
      "Preparing Routing Tables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Routing setup took 0:00:00.018043 \n",
      "Finding binaries\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: Graph binary gatherer took 0:00:00.034102 \n",
      "2024-04-25 11:50:07 INFO: Pair on chip router compression skipped as Tables already small enough\n",
      "Allocating SDRAM for SDRAM outgoing egde partitions\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:07 INFO: SDRAM outgoing partition allocator took 0:00:00.027159 \n",
      "Generating data specifications\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:08 INFO: Graph data specification writer took 0:00:00.375270 \n",
      "2024-04-25 11:50:08 INFO: Control Sync took 0:00:00.000745 \n",
      "loading fixed routes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:08 INFO: Load fixed routes took 0:00:00.058300 \n",
      "Executing data specifications and loading data for system vertices using Java\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:12 INFO: Load system data specification took 0:00:03.987616 \n",
      "Loading system executables onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:12 INFO: Load executable system Images took 0:00:00.309901 \n",
      "Clearing tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Loading Tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:12 INFO: Tags Loader took 0:00:00.027364 \n",
      "Executing data specifications and loading data for application vertices using Java\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:16 INFO: Load Application data specification took 0:00:04.195284 \n",
      "Preparing to Expand Neuron Data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Expanding Neuron Data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "\n",
      "Getting initial values\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:17 INFO: Neuron expander took 0:00:00.555090 \n",
      "Preparing to Expand Synapses\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Expanding Synapses\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "\n",
      "2024-04-25 11:50:18 INFO: Synapse expander took 0:00:00.926359 \n",
      "Finalising Retrieved Connections\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:18 INFO: Finish connection holders took 0:00:00.014707 \n",
      "Loading routing data onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:18 INFO: Routing table loader took 0:00:00.004889 \n",
      "2024-04-25 11:50:18 INFO: Bitfield compressor report skipped as cfg Reports:write_bit_field_compressor_report is False\n",
      "2024-04-25 11:50:18 INFO: Tags from machine report took 0:00:00.004654 \n",
      "2024-04-25 11:50:18 INFO: Memory report skipped as cfg Reports:write_memory_map_report is False\n",
      "2024-04-25 11:50:18 INFO: Memory report skipped as cfg Reports:write_memory_map_report is False\n",
      "Generating compressed router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating comparison of router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating Routing summary report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Reading Routing Tables from Machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:18 INFO: Compressor report took 0:00:00.051377 \n",
      "Writing fixed route report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:18 INFO: Fixed route report took 0:00:00.047472 \n",
      "Loading executables onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:19 INFO: Load executable app images took 0:00:00.555879 \n",
      "2024-04-25 11:50:19 INFO: Running for 1 steps for a total of 1000.0ms\n",
      "2024-04-25 11:50:19 INFO: Run 1 of 1\n",
      "Generating SDRAM usage report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:19 INFO: Sdram usage per chip report took 0:00:00.082616 \n",
      "2024-04-25 11:50:19 INFO: Drift report skipped as cfg Reports:write_drift_report_start is False\n",
      "2024-04-25 11:50:19 INFO: Creating live event connection database in /home/bbpnrsoa/Group5/reports/2024-04-25-11-49-43-931878/run_1/input_output_database.sqlite3\n",
      "Creating graph description database\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:19 INFO: Create database interface took 0:00:00.039252 \n",
      "2024-04-25 11:50:19 INFO: Create notification protocol took 0:00:00.008191 \n",
      "Waiting for cores to be either in PAUSED or READY state\n",
      "|0%                          50%                         100%|\n",
      " =================================================2024-04-25 11:50:19 INFO: ** Notifying external sources that the database is ready for reading **\n",
      "===========\n",
      "Updating run time\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:19 INFO: Runtime Update took 0:00:00.042805 \n",
      "2024-04-25 11:50:19 INFO: *** Running simulation... *** \n",
      "Loading buffers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:19 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2024-04-25 11:50:19 INFO: ** Sending start / resume message to external sources to state the simulation has started or resumed. **\n",
      "2024-04-25 11:50:19 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2024-04-25 11:50:19 INFO: Application started; waiting 10.1s for it to stop\n",
      "2024-04-25 11:50:29 INFO: ** Sending pause / stop message to external sources to state the simulation has been paused or stopped. **\n",
      "2024-04-25 11:50:29 INFO: Application runner took 0:00:10.225785 \n",
      "2024-04-25 11:50:29 INFO: Extract IO buff skipped as cfg Reports:extract_iobuf is False\n",
      "2024-04-25 11:50:29 INFO: Starting buffer extraction using Java\n",
      "2024-04-25 11:50:36 INFO: Buffer extractor took 0:00:07.067779 \n",
      "clearing IOBUF from the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:36 INFO: Clear IO buffer took 0:00:00.026761 \n",
      "Getting provenance data from application graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:36 INFO: Graph provenance gatherer took 0:00:00.047482 \n",
      "Getting provenance data\n",
      "|0%                          50%                         100%|\n",
      " ========================================================2024-04-25 11:50:37 WARNING: The weights from the synapses for TRN_pop(0:39) on 0,0,5 saturated 7 times. \n",
      "====\n",
      "2024-04-25 11:50:37 INFO: Placements provenance gatherer took 0:00:00.416276 \n",
      "Getting Router Provenance\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:37 INFO: Router provenance gatherer took 0:00:00.442049 \n",
      "Getting profile data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2024-04-25 11:50:37 INFO: Profile data gatherer took 0:00:00.059021 \n",
      "2024-04-25 11:50:37 INFO: Energy report skipped as cfg Reports:write_energy_report is False\n",
      "2024-04-25 11:50:37 INFO: Redundant packet count report took 0:00:00.006658 \n",
      "2024-04-25 11:50:37 INFO: Drift report skipped as cfg Reports:write_drift_report_end is False\n",
      "2024-04-25 11:50:37 INFO: Control Sync took 0:00:00.004360 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCR irregularity:  0.8270500641812415\n",
      "IN irregularity:  0.8585827081037454\n",
      "TRN irregularity:  0.7412603547664613\n",
      "TCR synchrony:  1.0895760549558393\n",
      "IN synchrony:  0.9994871794871794\n",
      "TRN synchrony:  2.4053809874723653\n",
      "12.737500000000008\n",
      "19.500000000000004\n",
      "33.925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84520122765e403480f9a06ada6fee92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copyright (c) 2020 The University of Manchester\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Modifications: Ported the model to Izhikevich's Conductance neurons\n",
    "Developed as a part of the undergraduate project by Ishita Mediratta under\n",
    "the guidance of Dr. Basabdatta Sen-Bhattacharya\n",
    "\n",
    "The model is given Poisson input in the beta range with parameters tuned in\n",
    "a way that they addhere to the plausible irregularity and synchrony values\n",
    "\n",
    "Original Implementation:\n",
    "\n",
    "Version uploaded on ModelDB October 2017.\n",
    "Author:\n",
    "Basabdatta Sen Bhattacharya, APT group, School of Computer Science,\n",
    "University of Manchester, 2017.\n",
    "\n",
    "If you are using the code,\n",
    "please cite the original work on the model - details are:\n",
    "\n",
    "B. Sen-Bhattacharya, T. Serrano-Gotarredona, L. Balassa, A. Bhattacharya,\n",
    "A.B. Stokes, A. Rowley, I. Sugiarto, S.B. Furber,\n",
    "\"A spiking neural network model of the Lateral Geniculate Nucleus on the\n",
    "SpiNNaker machine\", Frontiers in Neuroscience, vol. 11 (454), 2017.\n",
    "\n",
    "Free online access:\n",
    "https://journal.frontiersin.org/article/10.3389/fnins.2017.00454/abstract\n",
    "\"\"\"\n",
    "\n",
    "import pyNN.spiNNaker as p\n",
    "import numpy as np\n",
    "import math\n",
    "from pyNN.random import RandomDistribution, NumpyRNG\n",
    "\n",
    "# for plotting\n",
    "from pyNN.utility.plotting import Figure, Panel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pylint: disable=pointless-string-statement\n",
    "\n",
    "\n",
    "def get_mean_rate(numCells, population):\n",
    "    firing_rate = []      # format = < neuron_id, rate (spikes/ms) >\n",
    "\n",
    "    for index in range(0, numCells):\n",
    "        rate = len(population.segments[0].spiketrains[index])/TotalDuration\n",
    "        firing_rate.append(rate)\n",
    "\n",
    "    return sum(firing_rate)/len(firing_rate)\n",
    "\n",
    "\n",
    "def calc_irregularity(segment):\n",
    "    irregularity = 0\n",
    "    isi_array = []\n",
    "    for i in range(len(segment.spiketrains)):\n",
    "        if len(segment.spiketrains[i]) > 2:\n",
    "            isi_array.append([])\n",
    "            for j in range(len(segment.spiketrains[i])-1):\n",
    "                isi_array[-1].append(\n",
    "                    segment.spiketrains[i][j+1]-segment.spiketrains[i][j])\n",
    "    for i in range(len(isi_array)):\n",
    "        mean = np.mean(isi_array[i])\n",
    "        sd = np.std(isi_array[i])\n",
    "        cv = sd / mean\n",
    "        irregularity += cv\n",
    "    irregularity = irregularity / len(segment.spiketrains)\n",
    "    return irregularity\n",
    "\n",
    "\n",
    "def print_irregularity():\n",
    "    print(\"TCR irregularity: \", calc_irregularity(TCR_spikes.segments[0]))\n",
    "    print(\"IN irregularity: \", calc_irregularity(IN_spikes.segments[0]))\n",
    "    print(\"TRN irregularity: \", calc_irregularity(TRN_spikes.segments[0]))\n",
    "\n",
    "\n",
    "def calc_synchrony(segment):\n",
    "    spike_counts = np.zeros(int(TotalDuration/2.0), dtype=int)\n",
    "    for i in range(len(segment.spiketrains)):\n",
    "        for j in range(len(segment.spiketrains[i])):\n",
    "            index = math.floor(segment.spiketrains[i][j] / 2.0)\n",
    "            spike_counts[index] += 1\n",
    "    mean = np.mean(spike_counts)\n",
    "    var = np.std(spike_counts) * np.std(spike_counts)\n",
    "    synchrony = var / mean\n",
    "    return synchrony\n",
    "\n",
    "\n",
    "def print_synchrony():\n",
    "    print(\"TCR synchrony: \", calc_synchrony(TCR_spikes.segments[0]))\n",
    "    print(\"IN synchrony: \", calc_synchrony(IN_spikes.segments[0]))\n",
    "    print(\"TRN synchrony: \", calc_synchrony(TRN_spikes.segments[0]))\n",
    "\n",
    "\n",
    "\"\"\" Initialising Time and Frequency parameters \"\"\"\n",
    "\n",
    "# total duration of simulation\n",
    "TotalDuration = int(1000)\n",
    "\n",
    "# this is in ms.\n",
    "Duration_Inp = int(1000)\n",
    "\n",
    "# 50 ms at both start and end are disregarded to avoid transients\n",
    "Start_Inp = int(0)\n",
    "End_Inp = int(Start_Inp + Duration_Inp)\n",
    "\n",
    "Rate_Inp = int(22)\n",
    "Inp_isi = int(1000 / Rate_Inp)\n",
    "\n",
    "\"\"\" Initialising Model connectivity parameters \"\"\"\n",
    "\n",
    "intra_pop_delay = RandomDistribution('uniform', (1, 3))\n",
    "intra_nucleus_delay = RandomDistribution('uniform', (1, 3))\n",
    "inter_nucleus_delay = RandomDistribution('uniform', (1, 3))\n",
    "inter_pop_delay = RandomDistribution('uniform', (1, 3))\n",
    "input_delay = inter_pop_delay\n",
    "\n",
    "# # input_delay is the delay of the spike source hitting the neuronal pops\n",
    "# # inter_pop_delay is the delay of spike communication between the different\n",
    "# # populations of the model\n",
    "\n",
    "# probabilities\n",
    "p_trn2trn = 0.15\n",
    "p_in2tcr = 0.1545  # 0.232\n",
    "p_in2in = 0.236\n",
    "p_tcr2trn = 0.35\n",
    "p_trn2tcr = 0.1545  # 0.07\n",
    "p_ret2tcr = 0.07\n",
    "p_ret2in = 0.47\n",
    "\n",
    "# weights\n",
    "w_trn2trn = 1.0  # 0.06 # 1\n",
    "w_in2tcr = 0.1  # 2\n",
    "w_in2in = 0.35  # 2\n",
    "w_tcr2trn = 0.115  # 0.01 # 2 # 0.2 and 0.3 give best value -> 0.25\n",
    "w_trn2tcr = 0.03  # 2\n",
    "w_ret2tcr = 0.275  # 0.35 # 0.1 # 1\n",
    "w_ret2in = 0.275  # 0.35 # 0.1 # 1\n",
    "\n",
    "\"\"\" Initialising Izhikevich spiking neuron model parameters.\n",
    "We have used the conductance-based model here. \"\"\"\n",
    "\n",
    "# Tonic mode parameters\n",
    "tcr_a_tonic = 0.02\n",
    "tcr_b_tonic = 0.2\n",
    "tcr_c_tonic = -65.0\n",
    "tcr_d_tonic = 6.0\n",
    "tcr_v_init_tonic = RandomDistribution('uniform', (-63.0, -67.0),\n",
    "                                      rng=NumpyRNG(seed=85520))  # -65.0\n",
    "\n",
    "in_a_tonic = 0.1\n",
    "in_b_tonic = 0.2\n",
    "in_c_tonic = -65.0\n",
    "in_d_tonic = 6.0\n",
    "in_v_init_tonic = RandomDistribution('uniform', (-68.0, -72.0),\n",
    "                                     rng=NumpyRNG(seed=85521))  # -70.0\n",
    "\n",
    "trn_a_tonic = 0.02\n",
    "trn_b_tonic = 0.2\n",
    "trn_c_tonic = -65.0\n",
    "trn_d_tonic = 6.0\n",
    "trn_v_init_tonic = RandomDistribution('uniform', (-73.0, -77.0),\n",
    "                                      rng=NumpyRNG(seed=85522))  # -75.0\n",
    "\n",
    "tcr_a = tcr_a_tonic\n",
    "tcr_b = tcr_b_tonic\n",
    "tcr_c = tcr_c_tonic\n",
    "tcr_d = tcr_d_tonic\n",
    "tcr_v_init = tcr_v_init_tonic\n",
    "\n",
    "in_a = in_a_tonic\n",
    "in_b = in_b_tonic\n",
    "in_c = in_c_tonic\n",
    "in_d = in_d_tonic\n",
    "in_v_init = in_v_init_tonic\n",
    "\n",
    "trn_a = trn_a_tonic\n",
    "trn_b = trn_b_tonic\n",
    "trn_c = trn_c_tonic\n",
    "trn_d = trn_d_tonic\n",
    "trn_v_init = trn_v_init_tonic\n",
    "\n",
    "# tcr_b * tcr_v_init\n",
    "tcr_u_init = RandomDistribution('uniform', (-15.0, -11.0),\n",
    "                                rng=NumpyRNG(seed=85522))  # -13.0\n",
    "# in_b * in_v_init\n",
    "in_u_init = RandomDistribution('uniform', (-16.0, -12.0),\n",
    "                               rng=NumpyRNG(seed=85522))  # -14.0\n",
    "# trn_b * trn_v_init\n",
    "trn_u_init = RandomDistribution('uniform', (-17.0, -13.0),\n",
    "                                rng=NumpyRNG(seed=85522))  # -15.0\n",
    "\n",
    "# a constant DC bias current; this is used here for testing the RS and FS\n",
    "# characteristics of IZK neurons\n",
    "current_Pulse = RandomDistribution('poisson', lambda_=3.0,\n",
    "                                   rng=NumpyRNG(seed=85524))  # 5\n",
    "\n",
    "# excitatory input time constant\n",
    "tau_ex = 6.0\n",
    "\n",
    "# inhibitory input time constant\n",
    "tau_inh = 4.0\n",
    "\n",
    "# reversal potentials\n",
    "e_rev_ex = 0.0\n",
    "e_rev_inh = -80.0\n",
    "\n",
    "\"\"\" Starting the SpiNNaker Simulator \"\"\"\n",
    "p.setup(timestep=0.1)\n",
    "# set number of neurons per core to 50, for the spike source to avoid clogging\n",
    "# p.set_number_of_neurons_per_core(p.SpikeSourceArray, 50)\n",
    "\n",
    "\"\"\" Defining each cell type as dictionary \"\"\"\n",
    "\n",
    "# THALAMOCORTICAL RELAY CELLS (TCR)\n",
    "TCR_cell_params = {'a': tcr_a_tonic, 'b': tcr_b, 'c': tcr_c, 'd': tcr_d,\n",
    "                   'tau_syn_E': tau_ex, 'tau_syn_I': tau_inh,\n",
    "                   'i_offset': current_Pulse, 'e_rev_E': e_rev_ex,\n",
    "                   'e_rev_I': e_rev_inh\n",
    "                   }\n",
    "\n",
    "TCR_initial_values = {'v': tcr_v_init, 'u': tcr_u_init}\n",
    "\n",
    "# THALAMIC INTERNEURONS (IN)\n",
    "IN_cell_params = {'a': in_a, 'b': in_b, 'c': in_c, 'd': in_d,\n",
    "                  'tau_syn_E': tau_ex, 'tau_syn_I': tau_inh,\n",
    "                  'i_offset': current_Pulse, 'e_rev_E': e_rev_ex,\n",
    "                  'e_rev_I': e_rev_inh\n",
    "                  }\n",
    "\n",
    "IN_initial_values = {'v': in_v_init, 'u': in_u_init}\n",
    "\n",
    "# THALAMIC RETICULAR NUCLEUS (TRN)\n",
    "TRN_cell_params = {'a': trn_a, 'b': trn_b, 'c': trn_c, 'd': trn_d,\n",
    "                   'tau_syn_E': tau_ex, 'tau_syn_I': tau_inh,\n",
    "                   'i_offset': current_Pulse, 'e_rev_E': e_rev_ex,\n",
    "                   'e_rev_I': e_rev_inh\n",
    "                   }\n",
    "\n",
    "TRN_initial_values = {'v': trn_v_init, 'u': trn_u_init}\n",
    "\n",
    "\"\"\" Creating populations of each cell type \"\"\"\n",
    "scale_fact = 10\n",
    "NumCellsTCR = 8*scale_fact\n",
    "NumCellsIN = 2*scale_fact\n",
    "NumCellsTRN = 4*scale_fact\n",
    "TCR_pop = p.Population(\n",
    "    NumCellsTCR, p.extra_models.Izhikevich_cond, TCR_cell_params,\n",
    "    label='TCR_pop', initial_values=TCR_initial_values, seed=85520)\n",
    "IN_pop = p.Population(\n",
    "    NumCellsIN, p.extra_models.Izhikevich_cond, IN_cell_params,\n",
    "    label='IN_pop', initial_values=IN_initial_values, seed=85521)\n",
    "TRN_pop = p.Population(\n",
    "    NumCellsTRN, p.extra_models.Izhikevich_cond, TRN_cell_params,\n",
    "    label='TRN_pop', initial_values=TRN_initial_values, seed=85522)\n",
    "\n",
    "\"\"\" Poisson input for TCR \"\"\"\n",
    "spike_source_TCR = p.Population(\n",
    "    NumCellsTCR, p.SpikeSourcePoisson(rate=10, start=Start_Inp,\n",
    "                                      duration=Duration_Inp),\n",
    "    label='spike_source_TCR', seed=85523)\n",
    "\n",
    "\"\"\" Poisson input for IN \"\"\"\n",
    "spike_source_IN = p.Population(\n",
    "    NumCellsIN, p.SpikeSourcePoisson(rate=10, start=Start_Inp,\n",
    "                                     duration=Duration_Inp),\n",
    "    label='spike_source_IN', seed=85524)\n",
    "\n",
    "\"\"\" Poisson Source to TCR population projections \"\"\"\n",
    "Proj0 = p.Projection(\n",
    "    spike_source_TCR, TCR_pop, p.OneToOneConnector(),\n",
    "    p.StaticSynapse(weight=w_ret2tcr, delay=input_delay),\n",
    "    receptor_type='excitatory')\n",
    "\n",
    "\n",
    "\"\"\" Poisson Source2IN \"\"\"\n",
    "Proj1 = p.Projection(\n",
    "    spike_source_IN, IN_pop, p.OneToOneConnector(),\n",
    "    p.StaticSynapse(weight=w_ret2in, delay=input_delay),\n",
    "    receptor_type='excitatory')\n",
    "\n",
    "\n",
    "\"\"\" TCR2TRN \"\"\"\n",
    "Proj2 = p.Projection(\n",
    "    TCR_pop, TRN_pop, p.FixedProbabilityConnector(p_connect=p_tcr2trn),\n",
    "    p.StaticSynapse(weight=w_tcr2trn, delay=inter_nucleus_delay),\n",
    "    receptor_type='excitatory')\n",
    "\n",
    "\n",
    "\"\"\" TRN2TCR \"\"\"\n",
    "Proj3 = p.Projection(\n",
    "    TRN_pop, TCR_pop, p.FixedProbabilityConnector(p_connect=p_trn2tcr),\n",
    "    p.StaticSynapse(weight=w_trn2tcr, delay=inter_nucleus_delay),\n",
    "    receptor_type='inhibitory')\n",
    "\n",
    "\n",
    "\"\"\" TRN2TRN \"\"\"\n",
    "Proj4 = p.Projection(\n",
    "    TRN_pop, TRN_pop, p.FixedProbabilityConnector(p_connect=p_trn2trn),\n",
    "    p.StaticSynapse(weight=w_trn2trn, delay=intra_pop_delay),\n",
    "    receptor_type='inhibitory')\n",
    "\n",
    "\n",
    "\"\"\" IN2TCR \"\"\"\n",
    "Proj5 = p.Projection(\n",
    "    IN_pop, TCR_pop, p.FixedProbabilityConnector(p_connect=p_in2tcr),\n",
    "    p.StaticSynapse(weight=w_in2tcr, delay=intra_nucleus_delay),\n",
    "    receptor_type='inhibitory')\n",
    "\n",
    "\n",
    "\"\"\" IN2IN \"\"\"\n",
    "Proj6 = p.Projection(\n",
    "    IN_pop, IN_pop, p.FixedProbabilityConnector(p_connect=p_in2in),\n",
    "    p.StaticSynapse(weight=w_in2in, delay=intra_pop_delay),\n",
    "    receptor_type='inhibitory')\n",
    "\n",
    "\"\"\" Recording simulation data\"\"\"\n",
    "\n",
    "# recording the spikes and voltage\n",
    "spike_source_TCR.record(\"spikes\")\n",
    "spike_source_IN.record(\"spikes\")\n",
    "# spike_source_periodic_TCR.record(\"spikes\")\n",
    "# spike_source_periodic_IN.record(\"spikes\")\n",
    "TCR_pop.record((\"spikes\", \"v\", \"gsyn_exc\", \"gsyn_inh\"))\n",
    "IN_pop.record((\"spikes\", \"v\", \"gsyn_exc\", \"gsyn_inh\"))\n",
    "TRN_pop.record((\"spikes\", \"v\", \"gsyn_exc\", \"gsyn_inh\"))\n",
    "\n",
    "p.run(TotalDuration)\n",
    "\n",
    "\"\"\" On simulation completion, extract the data off the spinnaker machine\n",
    "memory \"\"\"\n",
    "\n",
    "# extracting the spike time data\n",
    "# spikesourcepattern_TCR = spike_source_periodic_TCR.get_data(\"spikes\")\n",
    "# spikesourcepattern_IN = spike_source_periodic_IN.get_data(\"spikes\")\n",
    "spikesourcepattern_TCR = spike_source_TCR.get_data(\"spikes\")\n",
    "spikesourcepattern_IN = spike_source_IN.get_data(\"spikes\")\n",
    "TCR_spikes = TCR_pop.get_data(\"spikes\")\n",
    "IN_spikes = IN_pop.get_data(\"spikes\")\n",
    "TRN_spikes = TRN_pop.get_data(\"spikes\")\n",
    "\n",
    "# extracting the membrane potential data (in millivolts)\n",
    "TCR_membrane_volt = TCR_pop.get_data(\"v\")\n",
    "IN_membrane_volt = IN_pop.get_data(\"v\")\n",
    "TRN_membrane_volt = TRN_pop.get_data(\"v\")\n",
    "\n",
    "# print TCR_membrane_volt.segments[0].analogsignals\n",
    "TCR_gsyn_e = TCR_pop.get_data(\"gsyn_exc\")\n",
    "IN_gsyn_e = IN_pop.get_data(\"gsyn_exc\")\n",
    "TRN_gsyn_e = TRN_pop.get_data(\"gsyn_exc\")\n",
    "\n",
    "TCR_gsyn_i = TCR_pop.get_data(\"gsyn_inh\")\n",
    "IN_gsyn_i = IN_pop.get_data(\"gsyn_inh\")\n",
    "TRN_gsyn_i = TRN_pop.get_data(\"gsyn_inh\")\n",
    "\n",
    "print_irregularity()\n",
    "print_synchrony()\n",
    "print(get_mean_rate(NumCellsTCR, TCR_spikes)*1000)\n",
    "print(get_mean_rate(NumCellsIN, IN_spikes)*1000)\n",
    "print(get_mean_rate(NumCellsTRN, TRN_spikes)*1000)\n",
    "\n",
    "\"\"\" Plotting \"\"\"\n",
    "\n",
    "Figure(\n",
    "    # raster plot of the presynaptic neuron spike times\n",
    "    Panel(TCR_spikes.segments[0].spiketrains, xlabel=\"Time/ms\",\n",
    "          xticks=True, ylabel=\"TCR Spikes Plots for TotalDuration\",\n",
    "          yticks=True, markersize=0.5, xlim=(1, TotalDuration), color='red'),\n",
    "    Panel(IN_spikes.segments[0].spiketrains, xlabel=\"Time/ms\",\n",
    "          xticks=True, ylabel=\"IN Spikes Plots for TotalDuration\",\n",
    "          yticks=True, markersize=0.5, xlim=(1, TotalDuration), color='red'),\n",
    "    Panel(TRN_spikes.segments[0].spiketrains, xlabel=\"Time/ms\",\n",
    "          xticks=True, ylabel=\"TRN Spikes Plots for TotalDuration\",\n",
    "          yticks=True, markersize=0.5, xlim=(1, TotalDuration), color='red'),\n",
    "    Panel(TCR_membrane_volt.segments[0].filter(name=\"v\")[0], xlabel=\"Time/ms\",\n",
    "          xticks=True, ylabel=\"TCR membrane voltage\",\n",
    "          yticks=True, markersize=0.5, xlim=(100, 400), legend=False),\n",
    "    Panel(IN_membrane_volt.segments[0].filter(name=\"v\")[0], xlabel=\"Time/ms\",\n",
    "          xticks=True, ylabel=\"IN membrane voltage\",\n",
    "          yticks=True, markersize=0.5, xlim=(100, 400), legend=False),\n",
    "    Panel(TRN_membrane_volt.segments[0].filter(name=\"v\")[0], xlabel=\"Time/ms\",\n",
    "          xticks=True, ylabel=\"TRN membrane voltage\",\n",
    "          yticks=True, markersize=0.5, xlim=(100, 400), legend=False),\n",
    "    title=\"Effect of I_DC on periodic input, with Izhikevich_cond neurons\",\n",
    "    annotations=\"Simulated with {}\".format(p.name())\n",
    ")\n",
    "# plt.savefig(\"Effect of I_DC on periodic input.png\")\n",
    "plt.show()\n",
    "\n",
    "p.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1596ca86-20a3-4dee-bc2b-54fb3d43c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signal(block):\n",
    "    # Extract the single AnalogSignal from the segment\n",
    "    signal = block.segments[0].analogsignals[0]\n",
    "    return np.array(signal)  # Convert to a NumPy array for easier manipulation\n",
    "\n",
    "# Extract excitatory conductance data\n",
    "TCR_gsyn_e_array = extract_signal(TCR_gsyn_e)\n",
    "IN_gsyn_e_array = extract_signal(IN_gsyn_e)\n",
    "TRN_gsyn_e_array = extract_signal(TRN_gsyn_e)\n",
    "\n",
    "# Similar blocks for inhibitory data\n",
    "TCR_gsyn_i_array = extract_signal(TCR_gsyn_i)\n",
    "IN_gsyn_i_array = extract_signal(IN_gsyn_i)\n",
    "TRN_gsyn_i_array = extract_signal(TRN_gsyn_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e890144-92b1-41ec-b784-410a059284fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1ee0e18656454fa043983cbd20118a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def combined_lfp_from_absolute_conductances(gsyn_e_tcr, gsyn_i_tcr, gsyn_e_in, gsyn_i_in, gsyn_e_trn, gsyn_i_trn):\n",
    "    # Sum absolute values of conductances across all neurons in each population and then across all populations\n",
    "    total_lfp = (np.sum(np.abs(gsyn_e_tcr) + np.abs(gsyn_i_tcr), axis=1) +\n",
    "                 np.sum(np.abs(gsyn_e_in) + np.abs(gsyn_i_in), axis=1) +\n",
    "                 np.sum(np.abs(gsyn_e_trn) + np.abs(gsyn_i_trn), axis=1))\n",
    "    return total_lfp\n",
    "\n",
    "# Generate the time array and plot LFP\n",
    "time_array = np.linspace(0, 1000, num=10000)  # Total time in ms\n",
    "combined_lfp = combined_lfp_from_absolute_conductances(\n",
    "    TCR_gsyn_e_array, TCR_gsyn_i_array,\n",
    "    IN_gsyn_e_array, IN_gsyn_i_array,\n",
    "    TRN_gsyn_e_array, TRN_gsyn_i_array\n",
    ")\n",
    "\n",
    "def plot_lfp(time_array, lfp_data, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time_array, lfp_data, label='Combined LFP from All Populations (Absolute Conductances)')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('LFP (arbitrary units)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_lfp(time_array, combined_lfp, 'Combined LFP from Absolute Sum of Conductances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60e141e-cf14-4d64-a4af-48fda9ce8f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19022a3f6b44a4da81986a87d2b6335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the get_data('v') method returns a Block that contains the AnalogSignal data\n",
    "tcr_v = TCR_membrane_volt.segments[0].analogsignals[0]\n",
    "in_v = IN_membrane_volt.segments[0].analogsignals[0]\n",
    "trn_v = TRN_membrane_volt.segments[0].analogsignals[0]\n",
    "\n",
    "\n",
    "# Function to calculate and plot the LFP from average membrane potentials of multiple neuron populations\n",
    "def plot_average_lfp(v_tcr, v_in, v_trn, times, title, ax):\n",
    "    # Convert to NumPy arrays if not already (depending on your framework)\n",
    "    v_tcr_array = np.array(v_tcr)\n",
    "    v_in_array = np.array(v_in)\n",
    "    v_trn_array = np.array(v_trn)\n",
    "\n",
    "    # Exclude the first 100 ms (1000 time points at 10,000 Hz)\n",
    "    slice_idx = 1000\n",
    "    v_tcr_sliced = v_tcr_array[slice_idx:, :]\n",
    "    v_in_sliced = v_in_array[slice_idx:, :]\n",
    "    v_trn_sliced = v_trn_array[slice_idx:, :]\n",
    "    times_sliced = times[slice_idx:]\n",
    "\n",
    "    # Calculate average membrane potential across all neurons in each population\n",
    "    avg_v_tcr = np.mean(v_tcr_sliced, axis=1)\n",
    "    avg_v_in = np.mean(v_in_sliced, axis=1)\n",
    "    avg_v_trn = np.mean(v_trn_sliced, axis=1)\n",
    "\n",
    "    # Combine averages from all populations, you might average them or sum them based on your definition of LFP\n",
    "    combined_avg_lfp = (avg_v_tcr + avg_v_in + avg_v_trn) / 3  # Averaging approach\n",
    "\n",
    "    # Plotting\n",
    "    ax.plot(times_sliced, combined_avg_lfp, alpha=0.5)  # Partial transparency\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Time (ms)', fontsize=14)\n",
    "    ax.set_ylabel('Average Membrane Potential (mV)', fontsize=14)\n",
    "    ax.legend(['Average LFP'], loc='upper right')\n",
    "\n",
    "# Assuming you already have the membrane potential arrays ready for TCR, IN, TRN populations\n",
    "tcr_times = np.linspace(0, 1000, num=10000)  # Time vector from 0 to 1000 ms with 10,000 points\n",
    "\n",
    "# Create subplot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Extract analog signals and convert to numpy arrays if needed\n",
    "tcr_v = np.array(TCR_membrane_volt.segments[0].analogsignals[0])\n",
    "in_v = np.array(IN_membrane_volt.segments[0].analogsignals[0])\n",
    "trn_v = np.array(TRN_membrane_volt.segments[0].analogsignals[0])\n",
    "\n",
    "# Plot average LFP from TCR, IN, TRN neurons\n",
    "plot_average_lfp(tcr_v, in_v, trn_v, tcr_times, 'Average LFP from TCR, IN, TRN Neurons', ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1287c5c-a58a-4921-a931-484b9c33f423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 80) (10000, 20) (10000, 40)\n"
     ]
    }
   ],
   "source": [
    "# Example on how to extract membrane potentials assuming data is stored in a structured way\n",
    "# This is hypothetical and depends on your specific data structure\n",
    "\n",
    "# Assuming 'TCR_membrane_volt', 'IN_membrane_volt', 'TRN_membrane_volt' are PyNN Block objects containing membrane potential data\n",
    "v_tcr = np.array(TCR_membrane_volt.segments[0].analogsignals[0])\n",
    "v_in = np.array(IN_membrane_volt.segments[0].analogsignals[0])\n",
    "v_trn = np.array(TRN_membrane_volt.segments[0].analogsignals[0])\n",
    "\n",
    "# Verify the extraction\n",
    "print(v_tcr.shape, v_in.shape, v_trn.shape)  # This should output the shape of the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f0cdaaa-8359-4898-b1c6-a3232e113995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume v_tcr, v_in, v_trn are your arrays containing membrane potentials for each population\n",
    "# These arrays should be NumPy arrays with dimensions [time, neurons]\n",
    "# Calculate the mean across neurons and then average these means across populations\n",
    "v_tcr_mean = np.mean(v_tcr, axis=1) if v_tcr.size else np.zeros_like(time_array)\n",
    "v_in_mean = np.mean(v_in, axis=1) if v_in.size else np.zeros_like(time_array)\n",
    "v_trn_mean = np.mean(v_trn, axis=1) if v_trn.size else np.zeros_like(time_array)\n",
    "\n",
    "combined_avg_lfp = (v_tcr_mean + v_in_mean + v_trn_mean) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50374392-1c4a-4527-afd7-27410478a4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1a964bc667441699117e2b400c4010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c97593d39974e3b9b9ec43d99b2e703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def perform_fft_and_plot_psd(lfp_data, sampling_rate, title):\n",
    "    n = len(lfp_data)\n",
    "    dt = 1 / sampling_rate\n",
    "    fft_result = np.fft.fft(lfp_data)\n",
    "    frequencies = np.fft.fftfreq(n, dt)\n",
    "    \n",
    "    # Only take the positive part of the spectrum\n",
    "    positive_indices = frequencies > 0\n",
    "    frequencies = frequencies[positive_indices]\n",
    "    fft_result = fft_result[positive_indices]\n",
    "\n",
    "    # PSD calculation\n",
    "    psd = np.abs(fft_result) ** 2 / (n * sampling_rate)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(frequencies, psd)\n",
    "    plt.title('PSD of ' + title)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('PSD [V²/Hz]')\n",
    "    plt.xlim(0, 100)  # Focus up to 100 Hz\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example parameters and usage\n",
    "sampling_rate = 10000  # This should match the actual sampling rate used in your data acquisition or simulation\n",
    "\n",
    "# Assuming `combined_lfp` is already calculated as the absolute summed LFP\n",
    "perform_fft_and_plot_psd(combined_lfp, sampling_rate, 'Combined LFP from Absolute Conductances')\n",
    "\n",
    "# Assuming `combined_avg_lfp` is calculated as the average of the membrane potentials\n",
    "perform_fft_and_plot_psd(combined_avg_lfp, sampling_rate, 'Average Membrane Potential LFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c4f8ce9-87f7-4736-8f9a-a7a5fb3d1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import gaussian, convolve\n",
    "\n",
    "def gaussian_kernel(size, sigma):\n",
    "    \"\"\" Generate a Gaussian kernel, used for smoothing the spike train. \"\"\"\n",
    "    kernel = gaussian(size, std=sigma, sym=True)\n",
    "    kernel /= kernel.sum()  # Normalize the kernel to ensure it sums to 1\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46842c33-8709-4bc6-8117-956f0df16728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-89d875f3ba9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m  \u001b[0;31m# Total time of the experiment in milliseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtime_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_continuous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_spikes_to_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_spike_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Plotting the continuous signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-89d875f3ba9c>\u001b[0m in \u001b[0;36mconvert_spikes_to_continuous\u001b[0;34m(spike_times, total_time, dt, kernel)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Convert spike times to indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_times\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcontinuous_signal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# Increment the bins where spikes occur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "def convert_spikes_to_continuous(spike_times, total_time, dt, kernel):\n",
    "    \"\"\" Convert discrete spike times to a continuous signal by convolution with a Gaussian kernel. \"\"\"\n",
    "    # Create a timeline with zero amplitude\n",
    "    time_array = np.linspace(0, total_time, int(total_time / dt) + 1)\n",
    "    continuous_signal = np.zeros_like(time_array)\n",
    "    \n",
    "    # Convert spike times to indices\n",
    "    indices = np.floor(spike_times / dt).astype(int)\n",
    "    continuous_signal[indices] += 1  # Increment the bins where spikes occur\n",
    "    \n",
    "    # Convolve the spike counts with the Gaussian kernel\n",
    "    smoothed_signal = convolve(continuous_signal, kernel, mode='same')\n",
    "    return time_array, smoothed_signal\n",
    "\n",
    "# Example usage with combined spike data\n",
    "kernel_size = 100  # Length of the kernel in samples\n",
    "sigma = 10  # Standard deviation of the Gaussian kernel\n",
    "kernel = gaussian_kernel(kernel_size, sigma)\n",
    "\n",
    "# Assuming `all_spike_times` contains combined spike times from all populations\n",
    "all_spike_times = np.concatenate([tcr_spike_times, in_spike_times, trn_spike_times])  # Concatenate spike times\n",
    "sampling_rate = 1000  # Hz\n",
    "dt = 1.0 / sampling_rate  # Time step in seconds\n",
    "total_time = 1000  # Total time of the experiment in milliseconds\n",
    "\n",
    "time_array, combined_continuous = convert_spikes_to_continuous(all_spike_times, total_time, dt, kernel)\n",
    "\n",
    "# Plotting the continuous signal\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_array, combined_continuous, label='Combined Continuous Signal from All Populations')\n",
    "plt.title('Continuous Signal from Combined Spike Data')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "222e4703-23bb-4eaa-8357-5c6e3c3d2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting spike times from the Segment objects\n",
    "def extract_spike_times(segment):\n",
    "    return [np.array(st.magnitude) for st in segment.spiketrains]\n",
    "\n",
    "# Using the extraction function on your existing data\n",
    "tcr_spike_times = extract_spike_times(TCR_spikes.segments[0])\n",
    "in_spike_times = extract_spike_times(IN_spikes.segments[0])\n",
    "trn_spike_times = extract_spike_times(TRN_spikes.segments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f28c3ab6-cc00-4781-87bf-a82b3ef69a88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gaussian' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1f1b8bc8cc63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m  \u001b[0;31m# in terms of number of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mstd_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# standard deviation in samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-10f15a4b6d5b>\u001b[0m in \u001b[0;36mgaussian_kernel\u001b[0;34m(size, sigma)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_spikes_to_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_times_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Create a timeline with zero amplitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gaussian' is not defined"
     ]
    }
   ],
   "source": [
    "def convert_spikes_to_continuous(spike_times, total_time, dt, kernel):\n",
    "    # Create a timeline with zero amplitude\n",
    "    continuous_signal = np.zeros(int(total_time / dt) + 1)\n",
    "    time_array = np.linspace(0, total_time, num=len(continuous_signal))\n",
    "    \n",
    "    # Increment the continuous signal at the indices of each spike time\n",
    "    indices = (spike_times / dt).astype(int)\n",
    "    indices = indices[indices < len(continuous_signal)]  # Ensure indices are within bounds\n",
    "    continuous_signal[indices] += 1\n",
    "    \n",
    "    # Convolve the spike signal with the kernel to smooth it\n",
    "    smoothed_signal = convolve(continuous_signal, kernel, mode='same')\n",
    "    return time_array, smoothed_signal\n",
    "\n",
    "# Create Gaussian Kernel\n",
    "kernel_size = 100  # in terms of number of samples\n",
    "std_dev = 10  # standard deviation in samples\n",
    "kernel = gaussian_kernel(kernel_size, std_dev)\n",
    "\n",
    "# Parameters\n",
    "sampling_rate = 1000  # Hz\n",
    "dt = 1.0 / sampling_rate\n",
    "total_time = 1000  # ms\n",
    "\n",
    "# Generate continuous signal for combined spikes\n",
    "combined_time, combined_continuous = convert_spikes_to_continuous(all_spike_times, total_time, dt, kernel)\n",
    "\n",
    "# Plotting the continuous signal\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(combined_time, combined_continuous, label='Combined Continuous Signal from All Populations')\n",
    "plt.title('Continuous Signal from Combined Spike Data')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ab3465e-2f47-4476-84b1-ae23f4194c82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_continuous' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d5eb5beb9f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Perform FFT and plot PSD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mperform_fft_and_plot_psd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_continuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PSD of Combined Continuous Signal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_continuous' is not defined"
     ]
    }
   ],
   "source": [
    "def perform_fft_and_plot_psd(signal, sampling_rate, title):\n",
    "    n = len(signal)\n",
    "    fft_result = np.fft.fft(signal)\n",
    "    frequencies = np.fft.fftfreq(n, 1 / sampling_rate)\n",
    "    \n",
    "    positive_frequencies = frequencies > 0\n",
    "    psd = np.abs(fft_result[positive_frequencies]) ** 2 / (n * sampling_rate)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(frequencies[positive_frequencies], psd)\n",
    "    plt.title('PSD of ' + title)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('PSD [V²/Hz]')\n",
    "    plt.xlim(0, 100)  # Up to 100 Hz\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Perform FFT and plot PSD\n",
    "perform_fft_and_plot_psd(combined_continuous, sampling_rate, 'PSD of Combined Continuous Signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba5087-f6d8-49f6-bc76-060895a57d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sPyNNakerGit",
   "language": "python",
   "name": "spynnakergit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
